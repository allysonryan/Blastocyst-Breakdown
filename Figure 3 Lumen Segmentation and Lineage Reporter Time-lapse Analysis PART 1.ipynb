{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import scipy.ndimage as ndi\n",
    "import sympy.geometry as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sympy import Point3D\n",
    "from skimage.morphology import disk\n",
    "from scipy.spatial.distance import cdist\n",
    "from skimage.segmentation import find_boundaries\n",
    "%matplotlib inline\n",
    "\n",
    "def real_space_convert(px_points, z_px_res, x_px_res, y_px_res):\n",
    "    \n",
    "    um_points = np.zeros_like(px_points)\n",
    "    points = px_points.shape[0]\n",
    "    \n",
    "    for point in range(points):\n",
    "        um_points[point, 0] = px_points[point, 0] * z_px_res\n",
    "        um_points[point, 1] = px_points[point, 1] * x_px_res\n",
    "        um_points[point, 2] = px_points[point, 2] * y_px_res\n",
    "        \n",
    "    return um_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and check dimensional order of timelapses\n",
    "fpath = r'---'\n",
    "fname = r'---.tif'\n",
    "img4d = io.imread(os.path.join(fpath,fname))\n",
    "print img4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# either add new axes if reduced dimensional timelapse (i.e. single channel or single timepoint) or roll axes until desired order is acheived'''\n",
    "AXIS_TO_BE_ROLLED = ---\n",
    "img4d = img4d[np.newaxis]\n",
    "img4d = np.rollaxis(img4d, AXIS_TO_BE_ROLLED)\n",
    "print img4d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pad image borders with empty pixels and create initial binary mask of cells and background subtracted images\n",
    "CH = ---\n",
    "PW= ---\n",
    "PW2 = PW+ PW\n",
    "MED_SIZE = ---\n",
    "\n",
    "img4d_p = np.zeros((img4d.shape[0],img4d.shape[1],img4d.shape[2],img4d.shape[3]+PW2,img4d.shape[4]+PW2),dtype=np.uint8)\n",
    "print img4d_p.shape\n",
    "img_rdy_4d     = np.zeros_like(img4d_p[:,CH,:,:,:])\n",
    "img_backsub_4d = np.zeros_like(img4d_p[:,CH,:,:,:])\n",
    "mask_4d        = np.zeros_like(img4d_p[:,CH,:,:,:])\n",
    "\n",
    "for timepoint in range(img4d.shape[0]):\n",
    "    \n",
    "    print 'timepoint ', timepoint\n",
    "    img = img4d[timepoint,CH,:,:,:]\n",
    "    print 'image shape', img.shape\n",
    "    \n",
    "    img_p = np.zeros((img.shape[0],img.shape[1]+PW2,img.shape[2]+PW2), dtype=np.uint8)\n",
    "    print 'padded image shape', img_p.shape\n",
    "    for z_slice in range(img_p.shape[0]):\n",
    "        img_p[z_slice,:,:] = np.pad(img[z_slice,:,:],pad_width=PW,mode='constant')\n",
    "    img4d_p[timepoint,CH,:,:,:] = img_p\n",
    "    \n",
    "    img_rdy = np.zeros_like(img_p)\n",
    "    print 'median filtered image shape', img_rdy.shape\n",
    "    for z_slice in range(img_p.shape[0]):\n",
    "        img_rdy[z_slice,:,:] = ndi.median_filter(img_p[z_slice,:,:], size=MED_SIZE)\n",
    "    img_rdy_4d[timepoint,:,:,:] = img_rdy\n",
    "    \n",
    "    stack_backsub = np.zeros_like(img_p)\n",
    "    print 'background subtracted image shape', stack_backsub.shape\n",
    "    stack_backsub[img_rdy>1] = img_rdy[img_rdy>1]\n",
    "    img_backsub_4d[timepoint,:,:,:] = stack_backsub\n",
    "\n",
    "    mask = np.zeros_like(img_p,dtype=np.bool)\n",
    "    print 'mask shape', mask.shape\n",
    "    for z_slice in range(img_p.shape[0]):\n",
    "        mask[z_slice,:,:] = stack_backsub[z_slice,:,:] > stack_backsub[z_slice,:,:].mean()\n",
    "    mask_4d[timepoint,:,:,:] = mask\n",
    "    \n",
    "io.imsave(os.path.join(fpath, fname[--:--] + '---.tif'),img_rdy_4d)\n",
    "io.imsave(os.path.join(fpath, fname[--:--] + '---.tif'),img_backsub_4d)\n",
    "io.imsave(os.path.join(fpath, fname[--:--] + '---.tif'),mask_4d.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean up binary mask and invert to obtain lumen segmentation\n",
    "se = disk(---)\n",
    "closed_mask_4d = np.zeros_like(mask_4d)\n",
    "seg_4d = np.zeros_like(mask_4d)\n",
    "\n",
    "for timepoint in range(mask_4d.shape[0]):\n",
    "    print 'timepoint ', timepoint\n",
    "    mask = mask_4d[timepoint,:,:,:]\n",
    "    \n",
    "    mask_rdy = np.zeros_like(mask)\n",
    "    for z_slice in range(mask.shape[0]):\n",
    "        #mask[z_slice,:,:] = ndi.binary_opening(mask[z_slice,:,:], structure=se, iterations=1)\n",
    "        mask_rdy[z_slice,:,:] = ndi.binary_closing(mask[z_slice,:,:], structure=se, iterations=15)\n",
    "    closed_mask_4d[timepoint,:,:,:] = mask_rdy\n",
    "\n",
    "    neg_space_objs,num_NSO = ndi.label(~mask_rdy.astype(bool))\n",
    "    seg_4d[timepoint,:,:,:] = neg_space_objs\n",
    "\n",
    "lumen = np.zeros_like(mask_4d)\n",
    "lumen[seg_4d>1] = seg_4d[seg_4d>1]\n",
    "\n",
    "io.imsave(os.path.join(fpath, '---' + fname),closed_mask_4d.astype(np.uint8))\n",
    "io.imsave(os.path.join(fpath, '---' + fname),seg_4d.astype(np.uint8))\n",
    "io.imsave(os.path.join(fpath, '---' + fname),lumen.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell below finding center of mass of Pdgfra signal & lumen boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find reporter center of mass and lumen boundaries\n",
    "fpath = r'---'\n",
    "fname_pdg = r'---.tif'\n",
    "fname_lumen = r'---.tif'\n",
    "\n",
    "pdg = io.imread(os.path.join(fpath,fname_pdg))\n",
    "print pdg.shape\n",
    "lumen = io.imread(os.path.join(fpath,fname_lumen))\n",
    "print lumen.shape\n",
    "\n",
    "z  = ---\n",
    "xy = ---\n",
    "\n",
    "lumen_boundaries = np.zeros_like(lumen)\n",
    "for timepoint in range(lumen.shape[0]):\n",
    "    print 'timepoint', timepoint\n",
    "    stack = lumen[timepoint,:,:,:]\n",
    "    boundaries = find_boundaries(stack)\n",
    "    lumen_boundaries[timepoint,:,:,:] = boundaries\n",
    "\n",
    "pdg_backsub = np.copy(pdg)\n",
    "pdg_centers = np.zeros((pdg.shape[0],3),dtype=np.float)\n",
    "for timepoint in range(pdg.shape[0]):\n",
    "    stack = pdg_backsub[timepoint,:,:,:]\n",
    "    stack_center = ndi.measurements.center_of_mass(stack)\n",
    "    print stack_center\n",
    "    pdg_centers[timepoint,:] = stack_center\n",
    "\n",
    "pdg_centers_um = real_space_convert(pdg_centers,z,xy,xy)\n",
    "lumen_boundary = np.zeros_like(pdg_centers)\n",
    "lumen_boundary_um = np.zeros_like(pdg_centers)\n",
    "distances = np.zeros((pdg.shape[0],1), dtype = np.float)\n",
    "\n",
    "for timepoint in range(lumen.shape[0]):\n",
    "    print 'timepoint ', timepoint\n",
    "    stack = lumen[timepoint,:,:,:]\n",
    "    if stack.max() > 0:\n",
    "        zB,yB,xB = np.where(lumen_boundaries[timepoint,:,:,:])\n",
    "        zB = np.reshape(zB,(len(zB),1))\n",
    "        yB = np.reshape(yB,(len(yB),1))\n",
    "        xB = np.reshape(xB,(len(xB),1))\n",
    "        coordinatesB = np.concatenate((zB,yB,xB),axis = 1)\n",
    "        print coordinatesB[1,:]\n",
    "        coordinatesB_um = real_space_convert(coordinatesB,z,xy,xy)\n",
    "        print coordinatesB_um[1,:]\n",
    "        pdg_center_um = np.reshape(pdg_centers_um[timepoint,:],(1,3))\n",
    "        all_distances = cdist(pdg_center_um,coordinatesB_um)\n",
    "        print all_distances.shape\n",
    "        min_dist = all_distances.min(axis = 1)\n",
    "        print min_dist.shape, min_dist\n",
    "        distances[timepoint,:] = min_dist\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "np.save(os.path.join(fpath,fname_pdg[--:--]   + '---'),pdg_centers)\n",
    "np.save(os.path.join(fpath,fname_pdg[--:--]   + '---'),pdg_centers_um)\n",
    "np.save(os.path.join(fpath,fname_lumen[--:--] + '---'),lumen_boundaries)\n",
    "np.save(os.path.join(fpath,fname_lumen[--:--] + '---'),lumen_boundary_um)\n",
    "np.save(os.path.join(fpath,fname_lumen[--:--] + '---'),lumen_boundary)\n",
    "np.save(os.path.join(fpath,fname_lumen[--:--] + '---'),distances)\n",
    "np.save(os.path.join(fpath,fname_lumen[--:--] + '---'),coordinatesB)\n",
    "np.save(os.path.join(fpath,fname_lumen[--:--] + '---'),coordinatesB_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove false positives from lumen segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove false positives from lumen segmentation\n",
    "fpath = r'---'\n",
    "fname = r'---.tif'\n",
    "img = io.imread(os.path.join(fpath,fname))\n",
    "print img.shape\n",
    "\n",
    "pL5voxel  = ---\n",
    "img = img.astype(bool)\n",
    "labeled_timelapse = np.zeros_like(img)\n",
    "for timepoint in range(img.shape[0]):\n",
    "    stack = img[timepoint,:,:,:]\n",
    "    labels, num_labels = ndi.label(stack)\n",
    "    \n",
    "    sizes = ndi.measurements.sum(stack,labels,index=range(num_labels+1))\n",
    "    print timepoint, num_labels, sizes\n",
    "    for index,size in enumerate(sizes):\n",
    "        if size < pL5voxel:\n",
    "            labels[labels == index] = 0\n",
    "    filt_sizes = ndi.measurements.sum(labels.astype(bool))\n",
    "    print 'filt sizes', filt_sizes\n",
    "    \n",
    "    ### JH's alternative to filter out objects below size threshold\n",
    "    ##unique_labels, unique_sizes = np.unique(label, return_counts=True)\n",
    "    ##labels[np.in1d(labels.flatten(), unique_labels[unique_sizes<---]).reshape(labels.shape)] = 0\n",
    "        \n",
    "    labeled_timelapse[timepoint,:,:,:] = labels\n",
    "    labeled_timelapse = labeled_timelapse.astype(bool)\n",
    "    \n",
    "io.imsave(os.path.join(fpath, fname[--:--] + '---.tif'),labeled_timelapse.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternative false positive removal method -- only retains the largest labeled object, not volume thresh based\n",
    "se = ball(---)\n",
    "ad_filt = np.zeros_like(labeled_timelapse.astype(np.uint8))\n",
    "for timepoint in range(labeled_timelapse.shape[0]):\n",
    "    \n",
    "    stack = labeled_timelapse[timepoint,:,:,:]\n",
    "    stack = ndi.binary_opening(stack,structure=se,iterations=1)\n",
    "    \n",
    "    labels, num_labels = ndi.label(stack)\n",
    "    sizes = ndi.measurements.sum(stack,labels,index=range(num_labels+1))\n",
    "    print 'number of labeled objects', num_labels\n",
    "    print 'embryo size', sizes.max()\n",
    "    \n",
    "    for index,size in enumerate(sizes):\n",
    "        if size < sizes.max():\n",
    "            labels[labels == index] = 0\n",
    "            \n",
    "    filt_sizes = ndi.measurements.sum(labels.astype(bool))\n",
    "    print 'filt sizes', filt_sizes\n",
    "    print 'embryo size retained', filt_sizes.max()\n",
    "    stack_filled = labels.astype(bool)\n",
    "    ad_filt[timepoint,:,:,:] = stack_filled\n",
    "\n",
    "io.imsave(os.path.join(fpath,fname[--:--] + '---.tif'),ad_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate lumen volume\n",
    "fpath = r'---'\n",
    "fname = r'---.tif'\n",
    "lumen_4d = io.imread(os.path.join(fpath,fname))\n",
    "print lumen_4d.shape\n",
    "print lumen_4d[lumen_4d[:,2]>0]\n",
    "\n",
    "timestep = 15\n",
    "start_time = 0\n",
    "z_res = 2\n",
    "xy_res = 0.2306294\n",
    "lumen_4d = lumen_4d.astype(bool)\n",
    "lumen_size = np.zeros((lumen_4d.shape[0],3),dtype=np.uint16)\n",
    "\n",
    "for timepoint in range(lumen_4d.shape[0]):\n",
    "    lumen = lumen_4d[timepoint,:,:,:]\n",
    "    size = np.sum(lumen)\n",
    "    size_pL = size*z_res*xy_res*xy_res*0.001\n",
    "    print size\n",
    "    lumen_size[timepoint,0] = timepoint\n",
    "    lumen_size[timepoint,1] = timepoint*timestep + start_time\n",
    "    lumen_size[timepoint,2] = size_pL\n",
    "print lumen_size\n",
    "\n",
    "np.save(os.path.join(fpath, fname[--:--] + '---.npy'),lumen_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sum reporter expression\n",
    "fpath = r'---'\n",
    "fname = r'---'\n",
    "pdg = io.imread(os.path.join(fpath,fname))\n",
    "print pdg.shape\n",
    "\n",
    "pdg_exp = np.zeros((pdg.shape[0],1),dtype=np.float)\n",
    "for timepoint in range(pdg.shape[0]):\n",
    "    \n",
    "    stack = pdg[timepoint,:,:,:]\n",
    "    exp_size = np.sum(stack.astype(bool))\n",
    "    stack_exp = np.sum(stack)/exp_size\n",
    "    \n",
    "    print stack_exp\n",
    "    pdg_exp[timepoint,:] = stack_exp\n",
    "    \n",
    "np.save(os.path.join(fpath, fname[--:--] + '---.npy'),pdg_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
